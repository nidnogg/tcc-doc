\chapter{CONCEITOS BÁSICOS\textbf{}}
\label{chp:capitulo2}

Nesse capítulo busca-se elucidar as principais terminologias, técnicas, algoritmos e tecnologias no geral que estão relacionadas a esse trabalho, realizando-se um apanhado geral e incluindo alguns exemplos esclarecedores.

\section{Injeção SQL}

O tipo mais comum e mais prevalecente de injeção de código é o da injeção SQL (em inglês: \textit{SQL Injection}), que manipula bancos de dados via SQL (abraviado do inglês: \textit{Structured Query Language}), a linguagem clássica de manuseio de bancos de dados, para receber acesso a informações sensíveis.

Exemplificando algumas situações de injeções SQL \cite{sql_port_swigger}:

\begin{alineas}
    \item 
    Consideremos uma aplicação que possui uma funcionalidade básica de login, com usuário e senha. Quando o usuário fornece as entradas \verb+‘usuário'+ e \verb+'123’+ como credenciais, a seguinte consulta SQL é realizada pelo sistema na checagem:
    
    \begin{verbatim}
        SELECT * FROM users 
        WHERE username = ‘usuario’ AND password = ‘123’
    \end{verbatim}
    
    Caso o usuário e senha sejam iguais a um registro na base de dados, todas as colunas da tabela \verb+user+ serão retornados. Caso contrário, os dados não serão obtidos.
    A sequência de caracteres \verb+--+ representa comentário em SQL. Se a aplicação não tiver uma higienização dos dados, é possível inserir esses caracteres como entrada e eles serão processados como uma instrução na consulta. Nesse caso, se o atacante usa a sequência de comentário SQL \verb+--+, ele é capaz de remover a checagem de senha da cláusula \verb+WHERE+. Por exemplo, se no parâmetro que é o \verb+username+ da consulta for inserido \verb+administrator’--+ e uma senha em branco, a seguinte consulta é processada:
    
    \begin{verbatim}
        SELECT * FROM users 
        WHERE username = 'administrator'--' AND password = '' 
    \end{verbatim}
    
    Isso efetivamente retorna os dados do usuário cujo \verb+username+ é \verb+administrator+ e realiza o login do atacante como tal, expondo funções sensíveis da aplicação web inteira.

    \item
    Em uma aplicação de e-commerce que organiza produtos em categorias diferentes, podemos ter um caso onde o usuário clica em uma categoria \verb+‘Presentes’+, requisitando o seguinte URL do navegador web:
    
    \textbf{https://insecure-website.com/products?category=Presentes}
    
    Isso faz com que a aplicação realize uma consulta SQL para resgatar todos os detalhes (identificado por \verb+*+) da tabela de produtos, onde a categoria é \verb+‘Presentes’+ e a restrição \verb+released+ é 1:
    
    \begin{verbatim}
        SELECT * FROM products
        WHERE category = ‘Presentes' AND released = 1 
    \end{verbatim}
    
    A restrição, quando observada por um atacante astuto, se revela como algo usado para esconder produtos não lançados. Esse atacante pode então construir um ataque digitando a seguinte URL, dado que o site não previne contra ataques SQL:
        
    \textbf{https://insecure-website.com/products?category=Presentes’--}
    
    Que provoca a seguinte consulta SQL:
    
    \begin{verbatim}
        SELECT * FROM products 
        WHERE category = 'Presentes'--' AND released = 1 
    \end{verbatim}
    
     Uma vez que a sequência \verb+--+ anteriormente vista denota um comentário SQL, a parte depois de 
    \verb+‘Presentes’+ é interpretada como tal e não é executada, revelando todos os produtos escondidos.

    \item
    Também é possível recuperar dados de outras tabelas de um banco de dados, utilizando a palavra chave \verb+UNION+ \cite{mysql_union}, que combina o resultado de múltiplas consultas \verb+SELECT+ em apenas um conjunto. Se um atacante executa a seguinte consulta contendo a entrada de usuário \verb+`Presentes`+, ainda no último exemplo de site:
    
    \begin{verbatim}
        SELECT name, description
        FROM products WHERE category = ‘Presentes'
    \end{verbatim}
    
    Então ele pode também submeter uma entrada nociva com \verb+UNION+:
    
    \begin{verbatim}
        ' UNION SELECT username, password FROM users--
    \end{verbatim}
        
    Tal entrada faz com que todos os usuários e senhas venham juntos das descrições dos supostos presentes, fundamentalmente comprometendo a segurança da aplicação

\end{alineas}


No contexto deste trabalho, é estudado o uso de WAFs, mais especificamente os baseados em técnicas de Aprendizado de Máquina, como forma de prevenir ataques. O uso de \textit{firewalls} para aplicações Web, tanto comerciais como de código aberto, tem tido amplo crescimento no mercado.

Além dos exemplos básicos de injeção SQL, existem variantes \cite{bach_owasp2020understanding} como: baseada em erro, baseada em união, às cegas e fora de banda. e \textit{out-of-band} \cite{out_of_band_sql_invicti}. Baseadas em erro são injeções que fornecem erros de SQL para o atacante, vazando informações críticas do banco de dados. Baseadas em união são ataques que utilizam uma consulta existente na lógica do sistema concatenada a outra através de um comando \verb+UNION+ de maneira a executar uma segunda lógica além daquela já estabelecida pelo sistema. Injeções às cegas (em inglês: \textit{blind-based}) são aquelas que o sistema não dá nenhuma informação após a injeção, de forma que o atacante precisa ser engenhoso para obter informações e prosseguir com a ofensiva. Uma injeção SQL fora de banda  é uma injeção sem o fornecimento de uma saída para o atacante, porém é possível tipicamente redirecionar a saída para um ponto como um servidor http.
É fundamental para mitigar as injeções ter uma validação dos caracteres e declarações válidas ao receber uma entrada de dados na aplicação web.

Injeção (em especial SQL) é uma das vulnerabilidades mais comuns, de baixa complexidade para o atacante e historicamente impactante, o que motivou o trabalho em aprofundar em um problema subestimado por desenvolvedores, que tem impactos profundos na confiabilidade, integridade e disponibilidade de um serviço web.

\section{Cross Site Scripting, ou XSS}
\textit{Cross Site Scripting}, também conhecida como XSS, é uma técnica onde geralmente há uma injeção de \textit{scripts} maliciosos na aplicação web, revelando dados sensíveis, serviços internos ou divulgação de \textit{cookies} de usuários com privilégios.
Existem três variantes de XSS. A primeira, XSS Armazenado, onde o atacante injeta uma entrada no servidor web, de maneira que quando outro usuário faz a requisição para acessar a página, essa entrada é ativada. A segunda, intitulada de XSS Refletido, ocorre quando o atacante injeta dados através de um método HTTP gerando uma resposta imediata na aplicação. Este permite o malfeitor forjar uma URL específica que ao ser acessada pela vítima vaza dados sensíveis, como \textit{cookies}. E por último a variante XSS baseada em DOM que consiste na inserção de código malicioso no DOM (\textit{Document Object Model}), sem refletir no código-fonte HTML, sendo ativado apenas pelo console DOM.
Dados obtidos de fontes não confiáveis devem ser devidamente validados e normalizados para evitar XSS.

\section{Algoritmos de Fuzzing}

O termo \textit{fuzz} foi cunhado pelo professor da Universidade de Wisconsin-Madison Barton Miller nos anos 80, após sofrer uma interferência por uma tempestade de raios atuando no funcionamento de aplicações que rodavam em um ambiente \textit{unix} remoto na época \cite{fuzzing_info}. 

Pouco depois disso o mesmo passou aos seus alunos uma tarefa denominada o \textit{"Fuzz Generator"}, na qual era necessário implementar uma ferramenta que testasse a robustez de programas \textit{unix} através de um bombardeio de informações aleatoriamente geradas.

Atualmente é uma técnica amplamente aceita na testagem/sondagem da segurança de diversas aplicações, com um leque de ofertas de \textit{fuzzing} comerciais no mercado. E naturalmente é empregável em WAFs, permitindo extrair informações valiosas que rendam aprimoramentos para os mesmos. Enquanto a ideia em si de \textit{fuzzing} permanece a mesma, as maneiras de efetuá-lo tiveram um grande progresso de mudança.


Uma função elementar de \textit{fuzzing} pode ser vista no Código 1, que constrói, a partir de tamanho máximo e caracteres no intervalo fornecidos pelo usuário, uma \textit{string} aleatória que pode ser chamada de \textit{string} "fuzzeada". Usa-se o pacote \verb+random+ para lidar com a aleatoriedade dos pedaços da \textit{string} que são construídos iterativamente. 

Essa \textit{string} serviria como entrada de um programa a ser testado, a fim de quebrá-lo e expor falhas/vulnerabilidades em sua implementação. Dependendo da complexidade do programa, pode servir como entrada tanto do fluxo de execução principal do programa ou em uma função menor do mesmo, para testar partes menores e afins. Não se usa sempre a mesma \textit{string} necessariamente, sendo comum a geração de várias delas para se ter uma testagem mais profunda.

\includecode[C]{Função de um \textit{fuzzer} elementar} {alg:codigo1}{codigos/fuzzer.py}

\bigskip
Tais funções de \textit{fuzzing} podem ser aprimoradas e customizadas para testar os mais diversos programas. Uma das maneiras de polir os resultados oriundos de \textit{fuzzing} elementar, que podem ser rejeitados facilmente por muitos programas inicialmente, é um processo chamado \textit{fuzzing} mutacional (em inglês: \textit{mutational fuzzing}), projetado para melhorar as chances de obter entradas maliciosas mas que são consideradas válidas pela aplicação testada.

Na estratégia de \textit{fuzzing} mutacional, a execução se inicia com uma entrada válida, e ela subsequentemente sofre uma mutação pequena, como no caso de uma \textit{string} a mudança de um caractere, adição/remoção de um número, ou até mesmo uma troca de um bit (todos naturalmente aleatórios, pelo princípio do funcionamento de \textit{fuzzing}).

\includecode[C]{Classe de \textit{fuzzer} mutacional} {alg:codigo1}{codigos/mutational_fuzzer.py}

\bigskip
O programa no Código 2 realiza, dentre os três métodos operadores de mutação acima do método \verb+mutate()+, uma mutação aleatória ao chamar \verb+mutate()+ propriamente dito. Realizar essa mutação consiste em executar um dos métodos (\verb+insert_random_character()+, \verb+delete_random_character()+, ou \verb+flip_random_character()+)  na entrada dada pelo usuário  \verb+mutate()+. 

Um desses métodos foi exemplificado e está comentado no código \linebreak (\verb+flip_random_character()+), e os demais são simples o suficiente para depreender o funcionamento dos comentários e nome do método.

Na prática, são realizadas uma série de mutações em cadeia, com o resultado de uma mutação servindo de entrada para a seguinte, para que se produzam entradas viáveis. Com um simples laço \verb+for+ ou \verb+while+ para chamar o método \verb+mutate()+ isso é possibilitado.

As técnicas de \textit{fuzzing} geralmente encontram erros de corrupção de memória simples, mas a aleatoriedade e dispersão fazem com que a eficiência do ataque seja baixa, cobrindo poucas partes do código. O \textit{fuzzing} aumenta seu potencial quando o alvo está em execução em um ambiente real. Outro ponto positivo é o fato de poder aplicar a técnica em aplicações sobre as quais há pouco conhecimento prévio.

Em suma, \textit{fuzzing} consiste na geração massiva de entradas normais e anômalas para uma aplicação específica, seguido da detecção de exceções no algoritmo devido o processamento das entradas geradas e monitoramento dos estados de execução da aplicação. Quando comparado com outras técnicas como análise estática, dinâmica e execução simbólica, o \textit{fuzzing} apresenta facilidade em ser implementado, boa precisão (em ambientes reais) e boa escalabilidade, sem acesso ao código fonte.

Expandindo um pouco o conceito, um teste de \textit{fuzzing} tipicamente consiste na geração em larga escala de entradas para um programa específico, entradas conhecidas também como casos de teste. A qualidade de tais casos de teste criados influencia diretamente na qualidade do teste \textit{fuzzing}. As entradas precisam atender os requisitos do programa testado para o padrão de entrada. Em contrapartida, as entradas precisam ser errôneas o suficiente para gerarem falhas ou erros no processamento do programa. De acordo com o alvo, as entradas podem ser arquivos com diferentes formatos, dados de comunicação entre redes, binários executáveis específicos, entre outros. No caso do \textit{wafamole++}, que é a aplicação alvo deste trabalho, trabalha-se com injeções SQL, nas quais é aplicada a técnica de \textit{fuzzing} iterativamente a fim de gerar uma entrada que consiga passar despercebido por um WAF avaliado, e seja malicioso. Essa entrada é o exemplo adversarial anteriormente mencionado.

Gerar casos de teste suficientemente errôneos é uma tarefa árdua, com duas variantes: \textit{fuzzing} baseado em geração, e \textit{fuzzing} mutacional, das quais a última é a adotada pelo \textit{WAF-A-MoLE} e \textit{wafamole++}. Depois de gerados, os casos de teste alimentam o programa alvo, tendo variáveis de ambiente e outros parâmetros do software a ser testado devidamente configurados pelo programador. Geralmente um teste de \textit{fuzzing} tem como condição final um tempo limite pré-definido ou uma falha de execução do programa.

\textit{Fuzzers} monitoram o estado de execução durante o processo, aguardando exceções ou falhas. Formas comuns de metodologia de monitoramento de exceções incluem monitorar sinais específicos do sistema, falhas e outras violações. Quando uma violação é capturada, o \textit{fuzzer} armazena o caso de teste que a causou para análise futura e replicação \cite{li2018fuzzing}.

Por fim, na fase de análise, tem-se por objetivo determinar a localidade e a causa da violação no software. A análise geralmente é feita com o auxílio de \textit{debuggers} como \verb+GDB+ \cite{gdb_docs}, \verb+windbg+ \cite{windbg_docs} ou outras ferramentas de análise binária, como o \verb+IDA Pro+ \cite{ida_pro_docs} e outras. O exato estado de execução dos casos de teste, informações da \textit{thread}, instruções e outras informações fazem parte do monitoramento. Para o caso do trabalho em questão, considerando-se o ambiente em \textit{Python}, o \textit{debugger} padrão \verb+pdb+ mostrou-se suficiente para diagnosticar a maioria dos erros encontrados. 

A Figura 1 ilustra uma visão de alto nível de um algoritmo de \textit{fuzzing}. Um caso teste é gerado, executado no programa, e caso o programa emita problemas (\textit{violation} no fluxograma), significa que existem erros a serem corrigidos. Caso contrário, mais casos teste são gerados até que erros sejam encontrados ou até o usuário parar a execução.

\begin{figure}[ht]
    \centering
    \caption{Workflow Fuzzing}
    \includegraphics[width=8cm,height=12cm,keepaspectratio]{figuras/fuzzing imagem.png} 
    \legend{Fonte: \href{https://cybersecurity.springeropen.com/track/pdf/10.1186/s42400-018-0002-y.pdf}{Li, J: Fuzzing - A Survey} (2018)}
    \label{fig:internet} 
\end{figure}

O \textit{fuzzer} baseado em geração necessita saber como é a entrada que o programa é capaz de processar. No caso de um \textit{fuzzing} para arquivos, geralmente é fornecido um arquivo de configuração com o modelo pré-definido de entrada. Os casos de teste são gerados de acordo com o arquivo de configuração. Fuzzers desse tipo tem facilidade em burlar validações do software testado, permitindo ao desenvolvedor entender com mais profundidade a aplicação estudada. Por outro lado, sem uma documentação amigável, analisar o formato do arquivo pode ser uma tarefa árdua.
Em termos de praticidade, \textit{fuzzers} mutacionais são mais fáceis de utilizar, com aplicabilidade genérica, sendo geralmente o tipo adotado por testes de intrusão no estado da arte. Diferente dos \textit{fuzzers} baseados em geração, o \textit{fuzzer} mutacional precisa de algumas entradas iniciais válidas. As entradas vão sofrendo mutações e novos casos de teste vão sendo gerados. O \textit{wafamole++} requer apenas uma entrada inicial válida - uma consulta que é fornecida pelo usuário no início da execução do programa.

O contexto relevante para o \textit{WAF-A-MoLE} é produzir, iterativamente, múltiplas injeções SQL a serem testadas a cada "rodada" de mutação. Uma injeção SQL é usada como base inicial, e a mesma sofre mutações por um \textit{fuzzer} dedicado até ser considerada válida pelo WAF testado, embora seja no fundo ainda uma injeção maliciosa. Dessa maneira, o \textit{wafamole++} pode ser resumidamente descrito como um \textit{fuzzer} mutacional, operando em cima de WAFs com entradas de injeções SQL "fuzzeadas".

\section{Aprendizado de Máquina}

Tendo seus primórdios em torno das décadas de 60 e 70, com dispositivos como o \textit{Cybertron} intitulados de "máquinas de aprendizado", esse subcampo de Inteligência Artificial teve uma tremenda ressurgência com recentes avanços em capacidade de processamento em tempos atuais. Com isso, dentre as áreas de interesse de computação enriquecidas por técnicas, naturalmente foram investigadas novas empreitadas em segurança da informação.

A ideia por trás de Aprendizado de Máquina \cite{dantas_transformers_2021} é o ensino/aprendizado de computadores por meio de exemplos - diferente da automação usual que envolve o programador elaborando algoritmos envolvendo manipulação de dados de entrada e saída desejados. Nesse contexto, um típico objetivo é rotular dados novos em categorias definidas nos dados iniciais. Para tal, temos dois principais procedimentos:
\begin{alineas}
\item \textbf{Aprendizado supervisionado} - em casos nos quais dados de entrada e saída de um algoritmo desse tipo são conhecidos, e o algoritmo resultando é aprimorado com base nisto.
\item \textbf{Aprendizado não-supervisionado} - casos nos quais os dados de saída não são conhecidos, sendo possível identificar padrões no próprio conjunto de entrada da aplicação.
\end{alineas}

Alguns termos de relevância dentro de tais procedimentos podem ser elencados:
\begin{alineas}
\item \textbf{Classificação} - É a ação qualitativa de rotular um dado avaliado com uma categoria, feito com um algoritmo de um classificador. Aplicando a um exemplo direto de Segurança da Informação, um classificador que rotula um pacote como "malicioso" realiza essa ação.
\item \textbf{Treinamento} - Essa ação envolve o fornecimento de exemplos para um determinado classificador, para que esse programa possa realizar a eventual classificação de dados vindouros. Com dados de texto, para o fornecimento desses exemplos ao classificador é comum passar os dados brutos por um algoritmo conhecido como vetorizador, que os transforma em vetores numéricos que serão lidos devidamente ao longo do treinamento.
\item \textbf{Dados de Teste} - São dados usados para a avaliação de um classificador realizada logo após seu treinamento, para que seja possível averiguar a eficácia e corretude do mesmo. É ideal ser uma porcentagem menor do que a de dados de validação, correspondendo usualmente em torno de 15\% a 30\% do conjunto de dados.
\item \textbf{Dados de Validação} - Durante o treinamento, são separados dados para a orientação do mesmo, com uso de uma parcela dos dados originais. É importante que esta parcela seja distinta dos dados de teste, para que o algoritmo resultante possa ter seu desempenho eventualmente testado contra dados completamente novos.

\end{alineas}


Sumariamente, o conhecimento de Aprendizado de Máquina traz abordagens
de automatização relevantes para o contexto deste trabalho, pois as aplicações de segurança usam diversos algoritmos oriundos desse subcampo de
Inteligência Artificial.

Algoritmos que vêm por padrão no \textit{WAF-A-MoLE} em modelos de exemplo são \textit{Naive Bayes}, Floresta Aleatória e Máquina de vetores de suporte Gaussiana/Linear, ofertados pela biblioteca \textit{scikit-learn}.

\subsection{Máquina de vetores de suporte}
Máquinas de vetores de suporte, popularmente abreviados como SVMs (do inglês \textit{Support Vector Machines}) são modelos de aprendizado supervisionado (dentro do contexto de teoria de Aprendizado de Máquina) associado a algoritmos de aprendizado que analisam dados para classificação e análise regressiva. É um dos métodos de predição mais robustos, baseado em arcabouços de aprendizado estatístico ou na teoria de Vapnik e Chervonenkis (comumente abreviada como teoria VC) \cite{vapnik_svm_support} \cite{ben2001_vapnik_support}.

Dado um conjunto de exemplos para treinamento, onde cada exemplo é marcado em uma de duas categorias, um algoritmo de treinamento SVM constrói um modelo que associa novos exemplos para uma categoria ou outra, sendo um classificador binário linear não-probabilístico. 
 
O SVM mapeia exemplos de treinamento para pontos no espaço de maneira a maximizar a distância entre as duas categorias. Novos exemplos são então mapeados no mesmo espaço. Em seguida, é feita uma predição sobre qual categoria o exemplo novo está associado.

Quando os dados ainda não foram rotulados, o aprendizado supervisionado não é possível e é necessário uma abordagem não-supervisionada, que tenta encontrar \textit{clusters} naturais para o grupo de dados e então mapear os novos dados nos grupos formados. 

O algoritmo \textit{SV clustering}, criado por Vladimir Vapnik \cite{ben2001_vapnik_support} com
outros parceiros na AT\&T Bell Laboratories, aplica a teoria estatística aos vetores de suporte, permitindo categorização de dados não-rotulados.

% Para exemplificar o poder do modelo de aprendizado, o artigo \cite{vapnik_svm_support} mostra a performance obtida em classificação de histogramas em níveis surpreendentemente altos, com taxas de erro por volta de 11\% (baixa) para a classificação de 14 categorias e com taxa de erro de 16\% para conjuntos de objetos mais genéricos. Esses resultados foram obtidos sem conhecimento prévio da tarefa, sabendo apenas que a entrada seria uma densidade discreta ou histograma colorido.

\textit{Python} possui no pacote \textit{sklearn} uma classe \verb+SVC+ (abreviação para \textit{Support Vector Classifier} em inglês, ou classificador de vetor de suporte) e variantes com eficácias distintas em cenários diferentes.

Além do desempenho como um classificador linear, SVMs conseguem efetuar classificações não-lineares utilizando um mapeamento implícito de entradas em espaços multi-dimensionais de maneira eficiente. O novo modelo proposto \textit{wafamole++} usa a versão não-linear, diferente da proposta no artigo original de Vladimir \cite{ben2001_vapnik_support}. Essa escolha é feita com base em experimentação de melhores resultados e uma otimização chamada \textit{GridSearchCV}, que sumariamente testa exaustivamente combinações possíveis dentro uma série de valores diferentes fornecidos para cada parâmetro de um classificador. 

Tomando um exemplo abstrato, com um classificador que possui um parâmetro determinado parâmetro chamado de \textbf{parametro\_a} (que pode assumir um valor numérico de 0 até 150), e um outro chamado de \textbf{parametro\_b} com um intervalo parecido. Para seu treinamento, pode-se fornecer à rotina \textit{GridSearchCV} o classificador e um conjunto de alternativas como 1, 10 e 100 no lugar desses parâmetros, e o treinamento do classificador será feito testando cada uma das possíveis combinações entre os conjuntos fornecidos para os parâmetros, sendo indicado no final qual seria o mais próximo do ideal. Essa otimização é também explorada mais adiante no Capítulo 4.

A Figura 2 ilustra visualmente as diferenças ao variar o parâmetro do \textit{kernel} em um classicador SVM na biblioteca \textit{scikit-learn}. O \textit{kernel} RBF (\textit{Radial Basis Function}) e polinomial de grau 3 correspondem aos não lineares, com o RBF sendo utilizado no \textit{wafamole++}. As zonas pintadas de azul e vermelho indicam elementos pertencentes a uma determinada predição feita pelo classificador, referente aos atributos de sépala de plantas na base de dados Íris (comumente usada no ensino e demonstração de Aprendizado de Máquina).

\begin{figure}[H]
    \centering
    \caption{Gráfico com quatro variantes do SVC}
    \includegraphics[width=14cm]{figuras/plot-svc.png} 
    \legend{Fonte: \href{https://scikit-learn.org/stable/modules/svm.html}{\cite{scikit_svm_module}} (2022)}
    \label{fig:internet} 
\end{figure}

\subsection{Gradiente Descendente Estocástico}

O Gradiente Descendente Estocástico (ou \textit{Stochastic Gradient Descent}, em inglês), comumente abreviado como SGD, é um método iterativo para otimização de uma função objetivo com propriedades "suaves" (diferenciais ou subdiferenciais) adequadas \cite{ruder2016overview}.

Pode ser considerada uma aproximação estocástica da otimização por gradiente descendente, uma vez que substitui o gradiente atual (calculado do conjunto de dados inteiro) por uma estimativa do mesmo calculada a partir um subconjunto dos dados selecionado aleatoriamente.

Em problemas de otimização com muitas dimensões isso reduz o custo computacional, tendo resultados mais rápidos com o \textit{tradeoff} de perda no que é chamado de taxa de convergência. Para melhor compreender esta taxa: no aprendizado supervisionado, uma função de perda é definida, possuindo um valor mínimo global que é buscado através do gradiente descendente. O quanto se aproxima desse valor com cada etapa/iteração do algoritmo é a taxa de convergência.

O SGD procura encontrar o mínimo global de uma função através de ajustes de configuração a cada tentativa. A Figura 3 mostra um exemplo dessa função, com valores mínimos/máximos globais e locais. Ao invés de reduzir o erro ou achar o gradiente para o conjunto de dados inteiro, o método reduz o erro através de aproximações em direção ao gradiente para um subconjunto aleatório do conjunto de dados, que pode ser tão pequeno quanto o conjunto de dados de treinamento inicial.

De forma heurística, se o modelo inicial erra muito, as alterações na configuração vão tornando o modelo mais preciso. Em contrapartida, é possível que questões antes acertadas, possam passar a serem classificadas como erradas ou pode acontecer um aumento da taxa de erro geral em favor de acertos específicos. Nem toda iteração necessariamente irá fazer o modelo melhorar.
Positivamente, o SGD consegue sair do mínimo local em direção ao mínimo global através dos ajustes de configuração com baixo custo computacional em relação ao gradiente descendente clássico \cite{overview_gradient_descent_stochastic}.

\begin{figure}[ht]
    \centering
    \caption{Função Objetivo}
    \includegraphics[width=10cm,height=14cm,keepaspectratio]{figuras/funcao_objetivo.png} 
    \legend{Fonte: \href{https://deepai.org/}{deepai.org} (2022)}
    \label{fig:internet} 
\end{figure}

No \textit{wafamole++}, um dos modelos novos é baseado em um classificador SGD, com seu funcionamento detalhado no Capítulo 4 e resultados demonstrados no Capítulo 5 após experimentos realizados.

% \includecode[C]{Função de um SGD elementar} {alg:codigo1}{codigos/sgd.py}

\bigskip

\subsection{AdaBoost}

O método de \textit{Boosting} vem da análise teórica do modelo de aprendizado chamado PAC (\textit{Probably Approximately Correct}). Os autores Kearns e Valiant propuseram os conceitos de aprendizado forte e fraco. No modelo de aprendizado do PAC, se um algoritmo de aprendizado polinomial para identificar um grupo de conceito tem uma acurácia de reconhecimento muito alta, esse algoritmo é considerado como aprendizado forte. Porém, se a taxa de corretude do algoritmo de aprendizado de identificação é um pouco superior à tentativa aleatória de adivinhar, então esse grupo é considerado aprendizado fraco. 

Kearns e Valient perceberam uma relação de equivalência entre aprendizado fraco e forte, onde o algoritmo de aprendizado fraco pode ser promovido para aprendizado forte, na qual a combinação dos resultados de uma série de algoritmos de aprendizados fracos (como tentativas de adivinhação aleatórias) gera o resultado um algoritmo de aprendizado forte. O requisito para isso é saber de antemão o algoritmo forte em específico.

Em 1990, Schapire publicou o primeiro método de \textit{Boosting} \cite{boosting_schapire1990strength}. \textit{Boosting} opera produzindo uma série de classificadores antes e depois do treinamento, que compartilham certos resultados durante o treinamento geral. O conjunto de treinamento utilizado em cada classificador é um subconjunto advindo do conjunto geral de treinamento e se cada amostra aparece no subconjunto ou não depende da performance dos classificadores anteriores. No caso das amostras julgadas como incorretas pelos classificadores produzidos anteriormente, a probabilidade de surgirem no novo subconjunto de treinamento será muito maior, fazendo com que os classificadores seguintes tenham foco em lidar com as diferenças nas amostras. Esse tratamento das diferenças seria uma tarefa árdua sem os resultados dos classificadores gerados na execução \cite{wu2011some}.

O método \textit{Boosting} pode aumentar a capacidade de generalização de um dado algoritmo, mas o algoritmo precisa ter estabelecido o limite inferior da acurácia de aprendizagem de um classificador fraco, que na prática é uma tarefa difícil.

O \textit{AdaBoost} é um algoritmo do tipo \textit{Boosting}, concebido em 1995 e publicado em 1999 \cite{adaboostfreund1999short}, com capacidade auto-adaptativa que melhora a performance de classificadores fracos por estabelecer um conjunto de múltiplos classificadores. 

Sendo o algoritmo mais representativo da família, ele mantém a distribuição de um conjunto de probabilidades para amostras de treinamento e ajusta a probabilidade de distribuição de cada amostra durante a iteração. Um algoritmo específico de aprendizado é usado para gerar um dos determinados classificadores gerados (dentre os vários anteriormente mencionados) e calcular a taxa de erro nas amostras de treinamento. O \textit{AdaBoost} irá usar a taxa de erro para ajustar a probabilidade de distribuição das amostras de treino. O papel de mudar os pesos é para aumentar o impacto das classificações incorretas e reduzir o impacto das classificações corretas. Por fim, com o ajuste dos pesos nos classificadores únicos, é obtido um classificador forte.

Essas características o tornaram um bom classificador para experimentar e o \textit{AdaBoost} eventualmente foi incorporado ao \textit{wafamole++}, na forma de um dos modelos novos. Sua performance é detalhada no Capítulo 5, de experimentação, e detalhes da sua implementação podem ser encontrados no Capítulo 4.

